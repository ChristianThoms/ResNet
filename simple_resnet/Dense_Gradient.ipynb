{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dense-Gradient.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "xl0g3Bnaln6-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def to_one_hot(y, no_labels):\n",
        "    arr = np.squeeze(np.eye(no_labels)[y])\n",
        "    return arr\n",
        "\n",
        "n_classes = 10\n",
        "cifar10 = tf.keras.datasets.cifar10.load_data()\n",
        "cifar10_train, cifar10_test = cifar10[0], cifar10[1]\n",
        "\n",
        "# use only first 25000 images (full dataset 50k)\n",
        "train_X = cifar10_train[0][:25000]\n",
        "cifar10_train_y = cifar10_train[1][:25000]\n",
        "\n",
        "test_X = cifar10_test[0][:25000]\n",
        "cifar10_test_y = cifar10_test[1][:25000]\n",
        "\n",
        "train_Y = to_one_hot(cifar10_train_y,n_classes)\n",
        "test_Y  = to_one_hot(cifar10_test_y, n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SIgdrV4guNU_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# resunit from first paper, conv -> batch -> relu -> conv batch -> shortcut addition -> relu\n",
        "def resUnit(input_layer,i):\n",
        "    with tf.variable_scope(\"res_unit\"+str(i)):\n",
        "        part1 = slim.conv2d(input_layer,64,[3,3],activation_fn=None)\n",
        "        part2 = slim.batch_norm(part1,activation_fn=None)\n",
        "        part3 = tf.nn.relu(part2)\n",
        "        part4 = slim.conv2d(part3,64,[3,3],activation_fn=None)\n",
        "        part5 = slim.batch_norm(part4,activation_fn=None)\n",
        "        shortcut = part5 + input_layer # remove input_layer here for 'plain' network\n",
        "        output = tf.nn.relu(shortcut)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h17GVDkPGlMI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# resnet from follow up paper, batch -> relu -> conv -> batch -> relu -> conv -> shortcut addition\n",
        "def resUnit2(input_layer,i):\n",
        "    with tf.variable_scope(\"res_unit\"+str(i)):\n",
        "        part1 = slim.batch_norm(input_layer,activation_fn=None)\n",
        "        part2 = tf.nn.relu(part1)\n",
        "        part3 = slim.conv2d(part2,64,[3,3],activation_fn=None)\n",
        "        part4 = slim.batch_norm(part3,activation_fn=None)\n",
        "        part5 = tf.nn.relu(part4)\n",
        "        part6 = slim.conv2d(part5,64,[3,3],activation_fn=None)\n",
        "        output = part6 + input_layer\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MKVmdsVf5Gk4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this is not working right now\n",
        "# tried to replace conv with dense layer\n",
        "def denseResNet(input_layer, i):\n",
        "    shortcut = input_layer\n",
        "    with tf.variable_scope(\"res_unit\"+str(i)):\n",
        "        part1 = slim.batch_norm(input_layer,activation_fn=None)\n",
        "        part2 = tf.nn.relu(part1)\n",
        "        #part3 = slim.conv2d(part2,64,[3,3],activation_fn=None)\n",
        "        part3 = tf.layers.dense(part2, part2.shape[1], activation=None)\n",
        "        part4 = slim.batch_norm(part3,activation_fn=None)\n",
        "        part5 = tf.nn.relu(part4)\n",
        "        part6 = tf.layers.dense(part5, part5.shape[1], activation=None)\n",
        "        #part6 = slim.conv2d(part5,64,[3,3],activation_fn=None)\n",
        "        output =  part6 + shortcut\n",
        "        print(input_layer.shape, part6.shape)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oo-crPVSl2Sg",
        "colab_type": "code",
        "outputId": "ff8144ee-fc20-4d63-c223-e4dc84a1dd97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow.contrib.slim as slim\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "total_layers = 1 # not used atm, Specify how deep we want our network\n",
        "units_between_stride = 2 # how many resUnits between a stride\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "\n",
        "# CIFAR10 data input (img shape: 32*32*3)\n",
        "n_input = 32\n",
        "n_depth = 3\n",
        "\n",
        "# input layer\n",
        "x = tf.placeholder(shape=[None,n_input,n_input,n_depth],dtype=tf.float32,name='input')\n",
        "label_layer = tf.placeholder(shape=[None],dtype=tf.int32)\n",
        "y = slim.layers.one_hot_encoding(label_layer, n_classes)\n",
        "\n",
        "\n",
        "layer1 = slim.layers.flatten(x)\n",
        "layer1 = tf.layers.dense(layer1, 3072, activation=tf.nn.sigmoid)\n",
        "\n",
        "for i in range(3):\n",
        "      layer1 = tf.layers.dense(layer1, layer1.shape[1], activation=tf.nn.sigmoid)\n",
        "\n",
        "# get 10 outputs for 10 classes\n",
        "top = tf.layers.dense(layer1, n_classes, activation=tf.nn.sigmoid)\n",
        "\n",
        "output = slim.layers.softmax(top)\n",
        "\n",
        "cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(output) + 1e-10, reduction_indices=[1]))\n",
        "trainer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "#update = trainer.minimize(cost)\n",
        "grads_and_vars = trainer.compute_gradients(cost)\n",
        "update = trainer.apply_gradients(grads_and_vars)\n",
        "\n",
        "correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
        "#calculate accuracy across all the given images and average them out. \n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KLbPPX5nl7Fx",
        "colab_type": "code",
        "outputId": "7b121363-736f-49de-b27b-2e898cb7b0d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1293
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "training_iters = 10\n",
        "with tf.Session() as sess:\n",
        "    saver = tf.train.Saver()\n",
        "    sess.run(init)\n",
        "    #saver.restore(sess, \"./plain2-20\")\n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    train_accuracy = []\n",
        "    test_accuracy = []\n",
        "    #summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
        "    \n",
        "    print(\"len\", len(train_X)//batch_size, len(train_X), batch_size)\n",
        "    for i in range(training_iters):\n",
        "        iter_loss = []\n",
        "        iter_accuracy = []\n",
        "        printed = False # only print the gradients for one batch, but in each training iteration\n",
        "        for batch in range(len(train_X)//batch_size):\n",
        "            batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
        "            batch_y = train_Y[batch*batch_size:min((batch+1)*batch_size,len(train_Y))]\n",
        "            # Run optimization op (backprop).\n",
        "            # Calculate batch loss and accuracy\n",
        "            for gv in grads_and_vars:\n",
        "                grads = sess.run(gv[0], feed_dict={x: batch_x, y: batch_y})\n",
        "                #print(gv[1].name, grads.shape)\n",
        "                if (\"dense_1/kernel\" in gv[1].name or \"dense_4/kernel\" in gv[1].name) and not printed: #41\n",
        "                    print(str(grads[0][:10]) + \" -\", gv[1].name, grads.shape, \"\\n\")\n",
        "                if (\"dense_1/bias\" in gv[1].name or \"dense_4/bias\" in gv[1].name) and not printed:\n",
        "                    print(str(grads[:10]) + \" -\", gv[1].name, grads.shape, \"\\n\")\n",
        "\n",
        "            printed = True # do not print again for another batch, next time will be in the next training iteration\n",
        "            opt = sess.run(update, feed_dict={x: batch_x, y: batch_y})\n",
        "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x, y: batch_y})\n",
        "\n",
        "            iter_loss.append(loss)\n",
        "            iter_accuracy.append(acc)\n",
        "\n",
        "        train_loss.append(sum(iter_loss)/(len(train_X)//batch_size))\n",
        "        train_accuracy.append(sum(iter_accuracy)/(len(train_X)//batch_size))\n",
        "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
        "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
        "                      \"{:.5f} \".format(acc), end='')\n",
        "\n",
        "        # Calculate accuracy for all test images\n",
        "        iter_loss = []\n",
        "        iter_accuracy = []\n",
        "        for batch in range(len(test_X)//batch_size):\n",
        "            batch_x = test_X[batch*batch_size:min((batch+1)*batch_size,len(test_X))]\n",
        "            batch_y = test_Y[batch*batch_size:min((batch+1)*batch_size,len(test_Y))]\n",
        "            valid_loss, test_acc = sess.run([cost, accuracy], feed_dict={x: batch_x, y: batch_y})\n",
        "            iter_loss.append(valid_loss)\n",
        "            iter_accuracy.append(test_acc)\n",
        "\n",
        "        \n",
        "        test_loss.append(sum(iter_loss)/(len(test_X)//batch_size))\n",
        "        test_accuracy.append(sum(iter_accuracy)/(len(test_X)//batch_size))\n",
        "        print(\"Testing Accuracy:\",\"{:.5f}\".format(test_accuracy[i]))\n",
        "    save_path = saver.save(sess, './orig2_resNet',global_step=training_iters)\n",
        "    \n",
        "    end = time.time()\n",
        "    print(\"duration:\", end-start)\n",
        "    \n",
        "    #summary_writer.close()\n",
        "    \n",
        "    #tvars = tf.trainable_variables()\n",
        "    #tvars_vals = sess.run(tvars)\n",
        "\n",
        "    #for var, val in zip(tvars, tvars_vals):\n",
        "        #print(var.name, val)  # Prints the name of the variable alongside its value."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len 390 25000 64\n",
            "[-4.1575827e-22  8.5311281e-22 -7.9517210e-22  7.0842537e-23\n",
            "  7.1489150e-22  2.4826940e-22  1.0753200e-21 -9.3620283e-23\n",
            " -1.5633921e-22  2.9381020e-22] - dense_1/kernel:0 (3072, 3072) \n",
            "\n",
            "[-3.3305082e-07  1.0113700e-05 -5.3744561e-06  9.9348358e-07\n",
            " -3.1010240e-06 -3.9314054e-06  3.2233872e-06 -1.3785571e-05\n",
            " -1.0149827e-05 -9.2219780e-06] - dense_1/bias:0 (3072,) \n",
            "\n",
            "[ 0.00635467 -0.0008898  -0.01240641 -0.00363719  0.00070055  0.00340486\n",
            "  0.0045593  -0.00150823  0.0089436  -0.00486355] - dense_4/kernel:0 (3072, 10) \n",
            "\n",
            "[ 0.01142841 -0.00164186 -0.02232053 -0.00648938  0.00120292  0.00618264\n",
            "  0.00814964 -0.00271715  0.01610724 -0.00872106] - dense_4/bias:0 (10,) \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-edd53f0f7876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Calculate batch loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0;31m#print(gv[1].name, grads.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"dense_1/kernel\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"dense_4/kernel\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprinted\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#41\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "rUiNQYV0aonC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}